{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26e7aa5-453d-4a51-9718-809c91f22233",
   "metadata": {},
   "source": [
    "# Desafio FieldPRO\n",
    "\n",
    "Neste notebook, abordaremos o desafio técnico proposto pela **FieldPro**, onde exploraremos e aplicaremos técnicas de análise de dados e _machine learning_ para resolver um problema específico. Ao longo deste notebook, iremos importar as bibliotecas necessárias, explorar os dados, criar e avaliar modelos preditivos. Vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0838931b-2bcf-4681-a5db-cb8db2f48966",
   "metadata": {},
   "source": [
    "## Desafio\n",
    "\n",
    "O objetivo deste desafio é construir um modelo de calibração de um sensor de chuva baseado em impactos mecânicos.\n",
    "\n",
    "O Sistema de medição de chuva funciona por meio de uma placa eletrônica com um piezoelétrico, um acumulador de carga e um sensor de temperatura. Os dados são transmitidos de hora em hora.\n",
    "\n",
    "O impacto das gotas de chuva gera vibrações no piezoelétrico, que induzem uma corrente elétrica. A corrente elétrica não é medida diretamente, mas é acumulada ao longo do tempo e gera uma queda na carga do acumulador.\n",
    "\n",
    "A carga do acumulador é medida de hora em hora e transmitida com o nome de `piezo_charge`. A temperatura da placa é transmitida sob o nome `piezo_temperature` e pode ser importante na calibração.\n",
    "\n",
    "Um evento de reset na placa pode afetar o comportamento do acumulador de carga, e o número total de resets da placa desde que foi ligada pela primeira vez é transmitido com nome `num_of_resets`.\n",
    "\n",
    "As medidas realizadas pelo sensor estão no arquivo **Sensor_FieldPRO.csv**, para comparação, foram utilizadas medidas de uma estação metereológica próxima, que estão no arquivo **Estacao_Convencional.csv**.\n",
    "\n",
    "Outras medidas do sensor incluem a carga medida no acumulador, a temperatura da placa, o número de resets da placa e as condições atmosféricas do ambiente.\n",
    "\n",
    "**Bônus**: Realizar o deploy do modelo em uma plataforma de cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae488592-7cf4-4dfc-bc97-7aaef5a15f34",
   "metadata": {},
   "source": [
    "## Entendendo o problema\n",
    "\n",
    "Com o objetivo de compreender melhor o problema e obter o máximo proveito do conjunto de dados disponível, iniciei uma pesquisa para entender o funcionamento de um sensor de chuva baseado em impactos mecânicos. Além disso, busquei explorar as possíveis relações entre a temperatura do ar, a umidade do ar e a pressão atmosférica, a fim de incorporar mais informações no treinamento do modelo e torná-lo mais robusto.\n",
    "\n",
    "A seguir, apresentam-se os títulos associados aos links consultados para esse propósito:\n",
    "\n",
    "- [Dew point](https://en.wikipedia.org/wiki/Dew_point)\n",
    "- [Estudo e desenvolvimento de um sensor de chuva piezoelétrico para automóveis](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://repositorio.ipl.pt/bitstream/10400.21/2544/1/Disserta%C3%A7%C3%A3o.pdf)\n",
    "- [Relações entre temperatura, umidade relativa do ar e pressão atmosférica em área urbana](https://periodicos.ufmg.br/index.php/geografias/article/view/13313)\n",
    "- [How do Rain Sensors Work](https://wiki.dfrobot.com/How_do_Rain_Sensors_Work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d694a3e-7f35-4193-9689-b9be057ca76e",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbd04074-01d8-4e1e-8f10-1c6d0d8f92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ffa43-7569-43e9-a390-b8bcfe392737",
   "metadata": {},
   "source": [
    "## Conjunto de dados\n",
    "\n",
    "Os dados do sensor estão armazenados no arquivo `Sensor_FieldPRO.csv`, enquanto para fins de comparação, foram utilizadas também medições de uma estação meteorológica próxima, que estão contidas no arquivo `Estacao_Convencional.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88200597-70e4-4dfd-a5ac-86889ba45c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor = pd.read_csv(\"dados/Sensor_FieldPRO.csv\")\n",
    "df_estacao = pd.read_csv(\"dados/Estacao_Convencional.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4acd1a-5e78-4410-bbf8-367131e6fd9c",
   "metadata": {},
   "source": [
    "## Verificação dos Tipos de Dados nos DataFrames\n",
    "\n",
    "Antes de iniciar qualquer análise ou modelagem, é importante conhecer os tipos de dados presentes nos DataFrames. Isso nos permitirá entender a natureza das informações que temos disponíveis e, se necessário, realizar conversões ou tratamentos específicos para preparar os dados para o modelo.\n",
    "\n",
    "Além de verificar os tipos de dados, também será útil visualizar as primeiras linhas dos DataFrames. Essa visualização inicial nos dará uma ideia geral do formato e conteúdo dos dados, permitindo identificar padrões ou possíveis problemas nas informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e4564f-03eb-41f3-a900-ff26f49f65d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime – utc</th>\n",
       "      <th>air_humidity_100</th>\n",
       "      <th>air_temperature_100</th>\n",
       "      <th>atm_pressure_main</th>\n",
       "      <th>num_of_resets</th>\n",
       "      <th>piezo_charge</th>\n",
       "      <th>piezo_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30T23:00:00Z</td>\n",
       "      <td>38.0</td>\n",
       "      <td>31.366</td>\n",
       "      <td>9412</td>\n",
       "      <td>0</td>\n",
       "      <td>45123</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-01T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9412</td>\n",
       "      <td>0</td>\n",
       "      <td>45025</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-01T01:00:00Z</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.366</td>\n",
       "      <td>9419</td>\n",
       "      <td>0</td>\n",
       "      <td>44923</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-01T02:00:00Z</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.322</td>\n",
       "      <td>9419</td>\n",
       "      <td>0</td>\n",
       "      <td>44825</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-01T03:00:00Z</td>\n",
       "      <td>38.0</td>\n",
       "      <td>31.240</td>\n",
       "      <td>9416</td>\n",
       "      <td>0</td>\n",
       "      <td>44728</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Datetime – utc  air_humidity_100  air_temperature_100  \\\n",
       "0  2020-09-30T23:00:00Z              38.0               31.366   \n",
       "1  2020-10-01T00:00:00Z               NaN                  NaN   \n",
       "2  2020-10-01T01:00:00Z              39.0               31.366   \n",
       "3  2020-10-01T02:00:00Z              39.0               31.322   \n",
       "4  2020-10-01T03:00:00Z              38.0               31.240   \n",
       "\n",
       "   atm_pressure_main  num_of_resets  piezo_charge  piezo_temperature  \n",
       "0               9412              0         45123                 30  \n",
       "1               9412              0         45025                 31  \n",
       "2               9419              0         44923                 31  \n",
       "3               9419              0         44825                 31  \n",
       "4               9416              0         44728                 31  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sensor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b98ff94-25d5-43c9-b0f3-af18392422f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime – utc          object\n",
       "air_humidity_100       float64\n",
       "air_temperature_100    float64\n",
       "atm_pressure_main        int64\n",
       "num_of_resets            int64\n",
       "piezo_charge             int64\n",
       "piezo_temperature        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sensor.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205d093e-162b-4286-957d-576bfcec039e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>Hora (Brasília)</th>\n",
       "      <th>chuva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data Hora (Brasília)  chuva\n",
       "0  2020-09-01        00:00:00    0.0\n",
       "1  2020-09-01        01:00:00    0.0\n",
       "2  2020-09-01        02:00:00    0.0\n",
       "3  2020-09-01        03:00:00    0.0\n",
       "4  2020-09-01        04:00:00    0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estacao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3096968f-eb99-4693-97a8-896d59728e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data                object\n",
       "Hora (Brasília)     object\n",
       "chuva              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estacao.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99303666-85ca-42c1-8bac-d487dde15136",
   "metadata": {},
   "source": [
    "Como a coluna `Datetime – utc` está no formato universal de hora (por exemplo: '2020-09-30T23:00:00Z'), faremos a conversão para o horário de Brasília. Em seguida, criaremos duas novas colunas: uma contendo apenas a data e outra com o horário no fuso horário de Brasília."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910bfcf5-723f-44a7-ad8b-60ab4b89c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor[\"data-hora(brasilia)\"] = pd.to_datetime(df_sensor['Datetime – utc'], format='mixed').dt.tz_convert(\"America/Sao_Paulo\")\n",
    "df_sensor[\"data\"] = df_sensor[\"data-hora(brasilia)\"].dt.strftime(\"%Y-%m-%d\")\n",
    "df_sensor[\"hora\"] = df_sensor[\"data-hora(brasilia)\"].dt.strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e17e28-7876-4c07-840a-280662862694",
   "metadata": {},
   "source": [
    "Observando o conjunto de dados, podemos perceber que a variável `piezo_charge` diminui ao longo do tempo. Portanto, criaremos uma nova coluna chamada `timeOn` que representa o tempo ligado a partir do reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff4c5e8a-c0d3-4fb0-a6f2-280b9564d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor['timeOn'] = 0\n",
    "\n",
    "# primeira data-hora do reset\n",
    "valores_num_of_resets = df_sensor['num_of_resets'].unique()\n",
    "primeira_ocorrencia = {}\n",
    "for valor in valores_num_of_resets:\n",
    "    mask = df_sensor['num_of_resets'] == valor\n",
    "    primeira_data = df_sensor.loc[mask, 'data-hora(brasilia)'].min()\n",
    "    primeira_ocorrencia[valor] = primeira_data\n",
    "\n",
    "for valor in valores_num_of_resets:\n",
    "    mask = df_sensor['num_of_resets'] == valor\n",
    "    primeira_data = primeira_ocorrencia[valor]\n",
    "    df_sensor.loc[mask, 'timeOn'] = (df_sensor.loc[mask, 'data-hora(brasilia)'] - primeira_data).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5dac7-5b80-435b-ab7a-d6498622ea4f",
   "metadata": {},
   "source": [
    "## Merge\n",
    "\n",
    "Para o treinamento do modelo, faremos a união dos DataFrames utilizando a data e hora como chave para a operação de merge. Essa abordagem garantirá que os dados sejam combinados de maneira coesa e organizada, preparando-os adequadamente para o processo de treinamento. Além disso, nesta etapa, realizaremos a remoção de dados nulos e a criação de novas features, com base em estudos das referências iniciais, visando enriquecer e aprimorar a qualidade dos dados para o desenvolvimento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1293a2c7-d4cb-4010-81b8-f3ee0d0fe835",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = df_sensor.merge(df_estacao, how='left', left_on=['data', 'hora'], right_on=['data', 'Hora (Brasília)'])\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db737359-3ea7-4edd-a326-8adf4df7b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_df[['data', 'hora', 'air_humidity_100', 'air_temperature_100', 'atm_pressure_main', 'num_of_resets', 'piezo_charge', 'piezo_temperature','timeOn', 'chuva']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff6f888-32f1-4861-88ff-1092e7be582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['air_humidity_100', 'air_temperature_100','chuva'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed494a-bee4-4b06-ab66-7d8e64efea29",
   "metadata": {},
   "source": [
    "### Ponto de orvalho\n",
    "\n",
    "O ponto de orvalho é uma temperatura crucial que pode auxiliar no modelo de análise. Ele representa a temperatura na qual o ar deve esfriar para que o vapor de água presente nele se condense e forme orvalho. Essa feature pode ser utilizada como uma variável relevante para enriquecer a análise do modelo, permitindo compreender melhor as condições ambientais e seus efeitos sobre a umidade do ar. Além disso, ao incorporar o ponto de orvalho como uma feature, o modelo pode obter insights mais precisos sobre a saturação de vapor de água no ar e sua relação com outros parâmetros meteorológicos, tornando-o mais robusto e confiável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e63a5e-565e-42c7-90d8-81d1f0fc0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nessa parte, estamos calculando a pressão parcial do vapor d'água no ar usando a fórmula empírica de August-Roche-Magnus. \n",
    "# Ela requer a umidade relativa do ar (como uma fração entre 0 e 1) e a temperatura do ar (em Celsius).\n",
    "\n",
    "df['pParcial'] = 243.04 * (np.log(df['air_humidity_100'] / 100) + (17.625 * df['air_temperature_100']) / (243.04 + df['air_temperature_100']))\n",
    "\n",
    "# Nessa parte, estamos calculando a pressão de vapor saturado do ar usando a mesma fórmula empírica de August-Roche-Magnus. \n",
    "# Novamente, ela requer a umidade relativa do ar (como uma fração entre 0 e 1) e a temperatura do ar (em Celsius).\n",
    "\n",
    "df['pVapor'] = 17.625 - (np.log(df['air_humidity_100']) + (17.625 * df['air_temperature_100']) / (243.04 + df['air_temperature_100']))\n",
    "\n",
    "# Aqui, dividimos a pressão parcial do vapor d'água pela pressão de vapor saturado do ar para calcular o ponto de orvalho\n",
    "\n",
    "df['ponto_de_orvalho'] = df['pParcial'] / df['pVapor'] - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e35768-01d0-4d4b-b6a4-6c68304b0c21",
   "metadata": {},
   "source": [
    "## Modelagem e Avaliação de Modelos de Machine Learning\n",
    "Nesta etapa, realizaremos a modelagem dos dados após o tratamento e preparação dos mesmos. Vamos explorar diferentes modelos de machine learning para encontrar aquele que melhor se ajusta ao nosso conjunto de dados.\n",
    "\n",
    "É importante ressaltar que nosso conjunto de dados é relativamente pequeno, o que requer atenção especial na escolha das métricas de avaliação. Dessa forma, daremos prioridade a métricas específicas de regressão, adequadas para avaliar o desempenho dos modelos que visam prever um valor numérico contínuo, que é a quantidade de chuva em milímetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7111311-c506-4419-a8f8-02f4fb193211",
   "metadata": {},
   "source": [
    "As principais métricas que iremos considerar para avaliar os modelos de regressão são: \n",
    "\n",
    "- Mean Absolute Error (MAE): Mede o erro médio absoluto entre as previsões do modelo e os valores reais. Essa métrica é menos sensível a outliers e pode ser mais estável em conjuntos de dados pequenos.\n",
    "\n",
    "- Mean Squared Error (MSE): Mede a média dos quadrados das diferenças entre as previsões do modelo e os valores reais. É mais sensível a erros maiores devido à sua natureza quadrática.\n",
    "\n",
    "- R² Score (Coefficient of Determination): Mede a proporção da variabilidade dos dados que é explicada pelo modelo. Um valor mais próximo de 1 indica um modelo que se ajusta bem aos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62ef0bc2-a62d-459c-ad4c-de725a9e592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['data', 'hora', 'chuva'])\n",
    "y = df['chuva']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c538d9-57fa-4c0e-972a-1d131a70346f",
   "metadata": {},
   "source": [
    "### Regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3e027bf-0937-4286-a86b-5cfa0472b8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de Regressão:\n",
      "Mean Absolute Error (MAE): 0.2127963444160296\n",
      "Mean Squared Error (MSE): 0.22661120665739\n",
      "R² Score (Coefficient of Determination): 0.029346035365224843\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculando as métricas de avaliação\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(\"Métricas de Regressão:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R² Score (Coefficient of Determination):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc73ea-491c-4813-b888-01c1f460fb99",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8ac9dd2-0f46-4605-b56f-11305c5bbd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de Regressão:\n",
      "Mean Absolute Error (MAE): 0.24786885245901638\n",
      "Mean Squared Error (MSE): 2.396590163934426\n",
      "R² Score (Coefficient of Determination): -9.265422344026844\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Métricas de Regressão:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R² Score (Coefficient of Determination):\", r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943cce8-7bfe-4854-822a-0ce946405b96",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f63168e-e615-40e3-aa75-09bbf66cb73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de Regressão:\n",
      "Mean Absolute Error (MAE): 0.2965631521005779\n",
      "Mean Squared Error (MSE): 0.2507742146236297\n",
      "R² Score (Coefficient of Determination): -0.07415246246234197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "grau = 2\n",
    "poly = PolynomialFeatures(grau)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred = linear_model.predict(X_test_poly)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)  # Renamed the variable to r_squared\n",
    "\n",
    "print(\"Métricas de Regressão:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R² Score (Coefficient of Determination):\", r_squared)  # Renamed the variable here as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f60e6-696c-4a91-880f-1146d8425007",
   "metadata": {},
   "source": [
    "### modelo SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "260c36b1-5a02-4735-8ff7-bc9afa432cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de Regressão:\n",
      "Mean Absolute Error (MAE): 0.15498961510288958\n",
      "Mean Squared Error (MSE): 0.2347857091403151\n",
      "R² Score (Coefficient of Determination): -0.005668178455031203\n"
     ]
    }
   ],
   "source": [
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svr_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Métricas de Regressão:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R² Score (Coefficient of Determination):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c4f1e-b8fb-49fe-9055-5ab7250c8517",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96e9f7e3-96d4-49b7-b7ec-86d179c01692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Metrics:\n",
      "Mean Absolute Error (MAE): 0.2010819672131147\n",
      "Mean Squared Error (MSE): 1.052076078688524\n",
      "R² Score (Coefficient of Determination): -3.5064047446707383\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Regressor Metrics:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R² Score (Coefficient of Determination):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6956a34-271b-4e38-aff7-d69e778843c2",
   "metadata": {},
   "source": [
    "### Conclusão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7cd3b-a794-4d4c-917d-04e64c4ee060",
   "metadata": {},
   "source": [
    "Após uma análise detalhada das métricas de desempenho dos modelos de regressão utilizados, chegou-se à conclusão de que o modelo SVR se destacou, demonstrando um desempenho superior em relação aos outros modelos testados. Isso indica uma maior capacidade de predição e uma melhor adaptação aos dados de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b004671-2e40-48e4-80ce-c39cc2a698f5",
   "metadata": {},
   "source": [
    "No entanto, ao observar o R² Score (Coefficient of Determination), nota-se que o valor foi próximo de zero e negativo. Esse resultado sugere que o modelo ainda não consegue explicar a variação total dos dados e pode indicar problemas na predição, como subajustamento aos dados de treinamento. Contudo, é fundamental ressaltar que esse comportamento pode ser atribuído ao tamanho relativamente pequeno do conjunto de dados utilizado no projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73f025-dbe5-40aa-8dab-f7c12924682f",
   "metadata": {},
   "source": [
    "À medida que o conjunto de dados é enriquecido com mais informações, o modelo SVR tem o potencial de alcançar um desempenho mais satisfatório, permitindo que ele aprenda padrões mais complexos e melhore sua capacidade de generalização. Portanto, futuros esforços de aprimoramento do modelo devem considerar a expansão do conjunto de dados, a fim de obter resultados mais representativos e precisos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeebfc1-9bba-4e96-85a3-4e154352f8f7",
   "metadata": {},
   "source": [
    "Em resumo, os resultados obtidos até o momento fornecem uma base sólida para prosseguir com o aperfeiçoamento do modelo SVR. O próximo passo consiste em buscar a otimização dos hiperparâmetros C e epsilon, além de continuar a coletar mais dados relevantes para melhorar a capacidade de predição do modelo e, assim, torná-lo mais aplicável a cenários complexos. Com essas melhorias, espera-se que o modelo SVR alcance seu máximo potencial e possa ser empregado de forma mais robusta em aplicações práticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2d439-4bd2-4d2e-af5d-2af3cd2cc7e3",
   "metadata": {},
   "source": [
    "### Otimizando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07055711-d2de-4b87-9c47-6c23e22c5ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'C': 10000, 'epsilon': 0.1}\n",
      "Métricas de Regressão (Melhor Modelo):\n",
      "Mean Absolute Error (MAE): 0.14891957708499207\n",
      "Mean Squared Error (MSE): 0.23366155058667878\n",
      "R² Score (Coefficient of Determination): -0.0008530196062681572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000, 10000],\n",
    "    'epsilon': [0.01, 0.1, 0.5, 1.0, 1.5, 2.0]   \n",
    "    }\n",
    "\n",
    "svr_model = SVR(kernel='rbf')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svr_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Melhores parâmetros:\", best_params)\n",
    "\n",
    "best_svr_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_svr_model.predict(X_test)\n",
    "\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"Métricas de Regressão (Melhor Modelo):\")\n",
    "print(\"Mean Absolute Error (MAE):\", mae_best)\n",
    "print(\"Mean Squared Error (MSE):\", mse_best)\n",
    "print(\"R² Score (Coefficient of Determination):\", r2_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83b3a3-c8c2-4d19-834f-9ee5b484538a",
   "metadata": {},
   "source": [
    "## **Bônus**: Realizar o deploy do modelo em uma plataforma de cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf7f73eb-4798-4cac-9e37-365e33b90c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svr_model.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svr_model, 'svr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a582d-1047-4f0a-bd50-96c851b99759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
